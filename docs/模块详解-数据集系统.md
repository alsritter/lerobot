# LeRobot 数据集系统详解 (Datasets Module)

## 概述

数据集模块是 LeRobot 框架的数据管理核心，负责机器人学习数据的采集、存储、加载和处理。该模块提供了统一的数据格式 LeRobotDataset，支持多种机器人任务的数据管理，并与 Hugging Face Hub 深度集成。

## 模块结构

```
datasets/
├── __init__.py              # 模块初始化和公共接口
├── lerobot_dataset.py       # LeRobotDataset 核心类
├── factory.py               # 数据集工厂函数
├── utils.py                 # 数据集工具函数
├── video_utils.py           # 视频处理工具
├── image_transforms.py      # 图像变换和增强
├── normalize.py             # 数据标准化
├── push_to_hub.py           # Hub 上传工具
└── transforms/              # 数据变换模块
    ├── __init__.py
    ├── image.py             # 图像变换
    ├── video.py             # 视频变换  
    └── utils.py             # 变换工具
```

## LeRobotDataset 核心类

### 数据格式规范
LeRobotDataset 采用统一的数据格式来存储机器人学习数据：

```python
class LeRobotDataset(torch.utils.data.Dataset):
    """LeRobot 统一数据集类"""
    
    def __init__(
        self,
        repo_id: str,
        split: str = "train",
        root: Optional[Path] = None,
        transform: Optional[Callable] = None,
        **kwargs
    ):
        """
        初始化数据集
        
        Args:
            repo_id: Hugging Face Hub 上的数据集 ID
            split: 数据集分割 (train/test/val)
            root: 本地数据根目录
            transform: 数据变换函数
        """
```

### 数据结构
每个数据样本包含以下字段：

```python
sample = {
    # 观测数据
    "observation.images.cam_high": torch.Tensor,      # 高位摄像头图像
    "observation.images.cam_low": torch.Tensor,       # 低位摄像头图像
    "observation.images.cam_wrist": torch.Tensor,     # 手腕摄像头图像
    "observation.state": torch.Tensor,                # 机器人状态 (关节位置等)
    
    # 动作数据
    "action": torch.Tensor,                           # 动作命令
    
    # 元数据
    "episode_index": int,                             # 回合索引
    "frame_index": int,                               # 帧索引
    "timestamp": float,                               # 时间戳
    "next.done": bool,                                # 回合结束标志
}
```

## 支持的数据类型

### 1. 图像数据
- **多摄像头支持**: 同时支持多个视角的图像
- **格式**: RGB, 深度图, 分割图
- **分辨率**: 灵活配置，支持不同分辨率
- **压缩**: JPEG 压缩存储，节省空间

### 2. 状态数据
- **关节状态**: 位置, 速度, 力矩
- **末端执行器**: 位置, 姿态, 夹爪状态
- **传感器数据**: 力传感器, IMU, 触觉传感器

### 3. 动作数据
- **控制命令**: 关节空间或笛卡尔空间
- **动作类型**: 位置控制, 速度控制, 力控制
- **时间信息**: 动作时间戳和持续时间

### 4. 元数据
- **回合信息**: 回合ID, 持续时间, 成功标志
- **任务信息**: 任务描述, 目标状态, 奖励信号
- **环境信息**: 环境配置, 物体位置, 场景描述

## 数据采集和存储

### 数据采集流程
```python
class DataRecorder:
    """数据记录器"""
    
    def __init__(self, output_dir: Path, fps: int = 30):
        self.output_dir = output_dir
        self.fps = fps
        self.episode_buffer = []
    
    def start_episode(self):
        """开始新的数据回合"""
        self.episode_buffer = []
    
    def record_frame(
        self, 
        observation: Dict[str, Any], 
        action: torch.Tensor
    ):
        """记录单帧数据"""
        frame_data = {
            "timestamp": time.time(),
            "observation": observation,
            "action": action
        }
        self.episode_buffer.append(frame_data)
    
    def end_episode(self, success: bool = True):
        """结束当前回合并保存数据"""
        self.save_episode(self.episode_buffer, success)
```

### 存储格式
LeRobot 使用高效的存储格式：

- **视频文件**: MP4 格式存储图像序列
- **状态数据**: Parquet 格式存储结构化数据
- **元数据**: JSON 格式存储描述信息
- **索引文件**: 快速访问和检索

```
dataset/
├── meta.json                    # 数据集元数据
├── stats.json                   # 数据统计信息
├── episode_0/
│   ├── observation.images.cam_high.mp4
│   ├── observation.images.cam_low.mp4
│   ├── observation.state.parquet
│   ├── action.parquet
│   └── metadata.json
├── episode_1/
│   └── ...
└── episode_N/
```

## 数据加载和预处理

### 数据加载器
```python
def create_dataloader(
    dataset: LeRobotDataset,
    batch_size: int = 32,
    shuffle: bool = True,
    num_workers: int = 4,
    **kwargs
) -> DataLoader:
    """创建数据加载器"""
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=dataset.collate_fn,
        **kwargs
    )
```

### 数据预处理管道
```python
class DataProcessor:
    """数据预处理器"""
    
    def __init__(self, config: Dict[str, Any]):
        self.image_transforms = self._build_image_transforms(config)
        self.state_normalizer = self._build_state_normalizer(config)
    
    def __call__(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """预处理数据样本"""
        # 图像预处理
        for key in sample.keys():
            if "image" in key:
                sample[key] = self.image_transforms(sample[key])
        
        # 状态数据标准化
        if "observation.state" in sample:
            sample["observation.state"] = self.state_normalizer(
                sample["observation.state"]
            )
        
        return sample
```

## 图像变换和增强

### 基础变换
```python
from lerobot.datasets.transforms.image import ImageTransforms

# 标准图像变换
transforms = ImageTransforms([
    ("resize", {"size": (224, 224)}),
    ("normalize", {"mean": [0.485, 0.456, 0.406], 
                   "std": [0.229, 0.224, 0.225]}),
    ("to_tensor", {})
])
```

### 数据增强
```python
# 训练时的数据增强
training_transforms = ImageTransforms([
    ("random_crop", {"size": (224, 224)}),
    ("random_horizontal_flip", {"p": 0.5}),
    ("color_jitter", {"brightness": 0.2, "contrast": 0.2}),
    ("random_rotation", {"degrees": 10}),
    ("normalize", {"mean": [0.485, 0.456, 0.406], 
                   "std": [0.229, 0.224, 0.225]}),
])
```

### 自定义变换
```python
class CustomAugmentation:
    """自定义数据增强"""
    
    def __init__(self, noise_std: float = 0.01):
        self.noise_std = noise_std
    
    def __call__(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        # 添加状态噪声
        if "observation.state" in sample:
            noise = torch.randn_like(sample["observation.state"]) * self.noise_std
            sample["observation.state"] += noise
        
        return sample
```

## 数据标准化

### 状态数据标准化
```python
class StateNormalizer:
    """状态数据标准化器"""
    
    def __init__(self, stats: Dict[str, Any]):
        self.mean = torch.tensor(stats["mean"])
        self.std = torch.tensor(stats["std"])
    
    def normalize(self, state: torch.Tensor) -> torch.Tensor:
        """标准化状态数据"""
        return (state - self.mean) / self.std
    
    def denormalize(self, normalized_state: torch.Tensor) -> torch.Tensor:
        """反标准化状态数据"""
        return normalized_state * self.std + self.mean
```

### 动作数据标准化
```python
class ActionNormalizer:
    """动作数据标准化器"""
    
    def __init__(self, action_bounds: Dict[str, torch.Tensor]):
        self.action_min = action_bounds["min"]
        self.action_max = action_bounds["max"]
    
    def normalize(self, action: torch.Tensor) -> torch.Tensor:
        """将动作标准化到 [-1, 1] 范围"""
        return 2.0 * (action - self.action_min) / (
            self.action_max - self.action_min
        ) - 1.0
```

## 视频处理

### 视频编解码
```python
class VideoProcessor:
    """视频处理器"""
    
    def __init__(self, fps: int = 30, codec: str = "h264"):
        self.fps = fps
        self.codec = codec
    
    def encode_video(
        self, 
        frames: List[np.ndarray], 
        output_path: Path
    ) -> None:
        """将图像序列编码为视频"""
        writer = cv2.VideoWriter(
            str(output_path),
            cv2.VideoWriter_fourcc(*self.codec.upper()),
            self.fps,
            (frames[0].shape[1], frames[0].shape[0])
        )
        
        for frame in frames:
            writer.write(frame)
        writer.release()
    
    def decode_video(self, video_path: Path) -> List[np.ndarray]:
        """解码视频为图像序列"""
        cap = cv2.VideoCapture(str(video_path))
        frames = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame)
        
        cap.release()
        return frames
```

### 多相机同步
```python
class MultiCameraVideoProcessor:
    """多相机视频处理器"""
    
    def __init__(self, camera_names: List[str]):
        self.camera_names = camera_names
    
    def sync_videos(
        self, 
        video_paths: Dict[str, Path]
    ) -> Dict[str, List[np.ndarray]]:
        """同步多个摄像头的视频"""
        # 读取所有视频
        all_frames = {}
        for cam_name in self.camera_names:
            all_frames[cam_name] = self.decode_video(video_paths[cam_name])
        
        # 时间同步对齐
        min_length = min(len(frames) for frames in all_frames.values())
        
        synced_frames = {}
        for cam_name in self.camera_names:
            synced_frames[cam_name] = all_frames[cam_name][:min_length]
        
        return synced_frames
```

## Hugging Face Hub 集成

### 数据集上传
```python
from lerobot.datasets.push_to_hub import push_dataset_to_hub

def upload_dataset(
    dataset_path: Path,
    repo_id: str,
    token: str
):
    """上传数据集到 Hugging Face Hub"""
    
    push_dataset_to_hub(
        dataset_path=dataset_path,
        repo_id=repo_id,
        token=token,
        commit_message="Add new robot dataset"
    )
```

### 数据集下载
```python
def download_dataset(repo_id: str, local_dir: Optional[Path] = None):
    """从 Hub 下载数据集"""
    
    dataset = LeRobotDataset(
        repo_id=repo_id,
        split="train",
        root=local_dir
    )
    
    return dataset
```

## 数据质量控制

### 数据验证
```python
class DataValidator:
    """数据质量验证器"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    def validate_episode(
        self, 
        episode_data: List[Dict[str, Any]]
    ) -> bool:
        """验证单个回合的数据质量"""
        
        # 检查数据完整性
        if len(episode_data) < self.config["min_episode_length"]:
            return False
        
        # 检查图像质量
        for frame in episode_data:
            if not self.validate_images(frame["observation"]):
                return False
        
        # 检查动作合理性
        if not self.validate_actions(episode_data):
            return False
        
        return True
    
    def validate_images(self, observation: Dict[str, Any]) -> bool:
        """验证图像质量"""
        for key, image in observation.items():
            if "image" in key:
                # 检查图像尺寸
                if image.shape != self.config["image_shape"]:
                    return False
                
                # 检查亮度
                brightness = torch.mean(image)
                if brightness < 0.1 or brightness > 0.9:
                    return False
        
        return True
```

### 异常检测
```python
class OutlierDetector:
    """异常值检测器"""
    
    def __init__(self, threshold: float = 3.0):
        self.threshold = threshold
    
    def detect_action_outliers(
        self, 
        actions: torch.Tensor
    ) -> torch.Tensor:
        """检测动作异常值"""
        
        # 计算 Z-score
        mean = torch.mean(actions, dim=0)
        std = torch.std(actions, dim=0)
        z_scores = torch.abs((actions - mean) / std)
        
        # 标记异常值
        outliers = torch.any(z_scores > self.threshold, dim=1)
        
        return outliers
```

## 数据统计和分析

### 统计信息计算
```python
class DatasetStatistics:
    """数据集统计信息"""
    
    def __init__(self, dataset: LeRobotDataset):
        self.dataset = dataset
    
    def compute_statistics(self) -> Dict[str, Any]:
        """计算数据集统计信息"""
        
        stats = {
            "num_episodes": self.dataset.num_episodes,
            "total_frames": len(self.dataset),
            "episode_lengths": [],
            "action_stats": {},
            "state_stats": {}
        }
        
        # 计算每个回合的长度
        for episode_idx in range(self.dataset.num_episodes):
            episode_length = self.dataset.episode_lengths[episode_idx]
            stats["episode_lengths"].append(episode_length)
        
        # 计算动作和状态统计
        all_actions = []
        all_states = []
        
        for sample in self.dataset:
            all_actions.append(sample["action"])
            all_states.append(sample["observation.state"])
        
        actions = torch.stack(all_actions)
        states = torch.stack(all_states)
        
        stats["action_stats"] = {
            "mean": torch.mean(actions, dim=0).tolist(),
            "std": torch.std(actions, dim=0).tolist(),
            "min": torch.min(actions, dim=0)[0].tolist(),
            "max": torch.max(actions, dim=0)[0].tolist()
        }
        
        stats["state_stats"] = {
            "mean": torch.mean(states, dim=0).tolist(),
            "std": torch.std(states, dim=0).tolist(),
            "min": torch.min(states, dim=0)[0].tolist(),
            "max": torch.max(states, dim=0)[0].tolist()
        }
        
        return stats
```

### 数据可视化
```python
class DataVisualizer:
    """数据可视化工具"""
    
    def __init__(self, dataset: LeRobotDataset):
        self.dataset = dataset
    
    def visualize_episode(self, episode_idx: int):
        """可视化单个回合"""
        
        # 获取回合数据
        episode_data = self.dataset.get_episode(episode_idx)
        
        # 创建图像网格
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # 显示不同摄像头的图像
        for i, (key, images) in enumerate(episode_data["images"].items()):
            if i < 3:
                axes[0, i].imshow(images[0])
                axes[0, i].set_title(f"{key} - Frame 0")
                
                axes[1, i].imshow(images[-1])
                axes[1, i].set_title(f"{key} - Frame {len(images)-1}")
        
        plt.tight_layout()
        plt.show()
```

## 性能优化

### 数据加载优化
- **并行加载**: 多进程数据读取
- **预取缓存**: 提前加载下一批数据
- **内存映射**: 大文件的高效访问
- **压缩优化**: 平衡压缩率和速度

### 存储优化
- **分块存储**: 大数据集的分块管理
- **索引优化**: 快速数据检索
- **缓存策略**: 热数据缓存
- **清理机制**: 自动清理临时文件

## 与其他模块的集成

### 与策略模块
- 提供训练和验证数据
- 支持在线学习场景
- 数据格式兼容性
- 批处理接口

### 与环境模块
- 环境状态记录
- 动作执行结果
- 奖励信号收集
- 回合边界标记

### 与摄像头模块
- 图像数据同步
- 多相机标定数据
- 实时数据流
- 质量监控

这个数据集模块为 LeRobot 提供了完整的数据管理解决方案，从数据采集到模型训练，确保了高质量的机器人学习数据流水线。